\documentclass[12pt,oneside]{scrartcl}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   Zusaetzliche Pakete  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{acronym}
\usepackage{enumerate}  
\usepackage{a4wide}
\usepackage[a4paper,bindingoffset=0.2in,%
            left=0.7in,right=0.7in,top=1.0in,bottom=1.0in,%
            footskip=0.25in]{geometry}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{palatino}
\usepackage{blindtext}
\usepackage{multirow}
\usepackage[ruled,longend]{algorithm2e}


%folgende Zeile auskommentieren für englische Arbeiten
\usepackage[ngerman]{babel}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[bookmarks]{hyperref}
\usepackage[font=small,labelfont=bf,justification=justified, format=plain]{caption}
\captionsetup[table]{singlelinecheck = off, justification=justified}
\captionsetup[figure]{justification=justified, singlelinecheck=off} 
\usepackage[style=authoryear-comp,natbib=true,backend=biber]{biblatex}
\usepackage{csquotes}
\addbibresource{literatur.bib}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% meine hinzugefügten Pakete %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\usepackage{float}

%% Caption für Bilder, Tabellen u.ä.
\usepackage{subcaption}
\usepackage{caption}

\usepackage[none]{hyphenat}
\sloppy
\usepackage{scrextend}

\deffootnote[1em]{1em}{1em}{\textsuperscript{\makebox[1em][l]{\thefootnotemark}}}

\usepackage{mathtools}
\usepackage[toc, page]{appendix}
\renewcommand\appendixtocname{Appendix}
\renewcommand\appendixpagename{Appendix}
\usepackage{mwe}
\usepackage{setspace}
\renewcommand{\baselinestretch}{1.25} % Zeilenabstand
\usepackage{tabularx}
\usepackage{multirow} % für Tabellen mit Multi-Spalten


% eingerückter Fußnotentext
\usepackage[hang, bottom]{footmisc} % Fußnoten am Ende der Seite und hängend
\setlength\footnotemargin{10pt}

%% Definition einer dickeren hline %%
\makeatletter
\def\thickhline{%
  \noalign{\ifnum0=`}\fi\hrule \@height \thickarrayrulewidth \futurelet
   \reserved@a\@xthickhline}
    \def\@xthickhline{\ifx\reserved@a\thickhline
                   \vskip\doublerulesep
                   \vskip-\thickarrayrulewidth
                 \fi
      \ifnum0=`{\fi}}
\makeatother

\newlength{\thickarrayrulewidth}
\setlength{\thickarrayrulewidth}{3\arrayrulewidth}

\usepackage{xurl} % Schönere Anzeige der URLs

\usepackage[export]{adjustbox} % für left aligned Bilder

\usepackage{makecell} % für Zellen in Tabellen, um so was wie Linebreaks zu ermöglichen

\usepackage{enumitem} % für bessere Kontrolle über Aufzählungsitems

\newcommand{\tabitem}{~~\llap{\textbullet}~~} % für items innerhalb von Tabellen 

\usepackage{enumitem}
\setlist{leftmargin=5.5mm} % Bulletpoints werden weiter nach links verlegt

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Definition der Kopfzeile %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagestyle{fancy}
\fancyhf{}
\cfoot{\thepage}
\setlength{\headheight}{16pt}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  Definition des Deckblattes und der Titelseite  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\JMUTitle}[9]{

  \thispagestyle{empty}
  \vspace*{\stretch{1}}
  {\parindent0cm
  \rule{\linewidth}{.7ex}}
  \begin{center} %%Rechts: flushright
    \vspace*{\stretch{1}}
    \sffamily\bfseries\Huge
    #1\\
    \vspace*{\stretch{1}}
    \sffamily\bfseries\large
    #2
    \vspace*{\stretch{1}}
  \end{center} %%Rechts: flushright
  \rule{\linewidth}{.7ex}

  \vspace*{\stretch{1}}
  \begin{center}
    \includegraphics[width=2in]{siegel} \\
    \vspace*{\stretch{1}}
    \Large Seminararbeit  \\

    \vspace*{\stretch{2}}
   \large Institut für deutsche Philologie \\
          Lehrstuhl für Computerphilologie\\ und Neuere Deutsche Literaturgeschichte\\
    \vspace*{\stretch{1}}
    \large Dozent:  #7 \\[1mm]
    \large Seminar: Textklassifikation \\[1mm]
    
    \vspace*{\stretch{1}}
    \large W\"urzburg, den #6
  \end{center}
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  Beginn des Dokuments  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
  \JMUTitle
    %TODO
      {Epocheneinteilung der Lyrik in der Frühen Moderne mit BERT} % Titel der Arbeit
      {Jan Paulus} % Vor- und Nachname des Autors
      
      {Institut für deutsche Philologie
Lehrstuhl für Computerphilologie und Neuere Deutsche Literaturgeschichte}  % Name der Fakultaet
      {W"urzburg 2020} % Ort und Jahr der Erstellung
      {13.02.2020} % Tag der Abgabe
      {Prof. Dr. Fotis Jannidis} % Name des Erstgutachters
      {Zweitgutachter} % Name des Zweitgutachters
      {Pr"ufungsdatum} % Datum der muendlichen Pruefung

  \clearpage
\sloppy
\lhead{}
\pagenumbering{Roman} 
    \setcounter{page}{1}

\tableofcontents
\clearpage

\addcontentsline{toc}{section}{\listfigurename}
\listoffigures

\addcontentsline{toc}{section}{\listtablename}
\listoftables
\clearpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  Einstellungen  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\cleardoublepage
\pagenumbering{arabic}  
    \setcounter{page}{1}
\lhead{\nouppercase{\leftmark}}
\setkomafont{sectioning}{\bfseries\scshape} %different section styling

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  Hauptteil  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{TODO, IDEEN}

\begin{itemize}
    \item TODO: perplexity
    \item TODO: Figures richtig einstellen, dass sie nicht zu viel platz übrig lassen 
    \item TODO: Einleitung richtig überprüfen, auch nach Formulierungen und so. wurde alles erklärt?
    \item TODO: stilometrie forschung mit einbeziehen. ICH: wirklich? vllt in Einleitung nach epochen erklärung
    \item TODO: Domänenadaption erklären
    \item TODO: Erklären, wieso LR, SVM
    \item TODO: Evaluation erklären: McNemar Test
    \item TODO?: historische deutsche word embeddings verwenden \href{https://nlp.stanford.edu/projects/histwords/}{LINK}
    \item TODO: (indirekt) erklären, dass XLNet nicht ging, da nur BERT deutsche Modelle
    \item Literatur Zitierung überprüfen
    \item wichtige Verfahren mit \textsc{Kapitälchen} highlighten
    \item Ngramme bei Ml-clf verwenden
\end{itemize}

PROBLEME?
\begin{itemize}
    \item Epocheneinteilung des Naturalismus und der Jahrhundertwende. TODO: verschiedene Grenzen ausprobieren und auch problematische Autoren durch Confusion Matrix ermitteln. Diese eventuell dann anderer Epoche zuordnen.
\end{itemize}

LITERATUR
\begin{itemize}
    \item WIELAND 2019: Einteilung von Epochen
    \item HAIDER 2019: DLK-Korpus, macht ansonsten aber eher Topic Modelling
    \item DHD2019, S. 66, HAIDER Vortrag: Klassifizierung in Zeitfenster und Autorschaft zwar vielversprechend, für bessere Themenmodelle im Sinne klarer Trend- und Top-Themen wäre jedoch eine bessere Grundlage für die Modellierung diachroner Transformationen in der Poesie notwendig.
    \item DHD2020, S. 127, KRAUTTER paper: TODO
\end{itemize}

NOTIZEN

TODO: signal muss nicht unbedingt epoche sein?
TODO: autoren wurde nach neue deutsche biographie händisch in epochen extra unterteilt. ICH: gucken, wie sich das unterscheidet von epocheneinteilung nach jahreszahlen
TODO/IDEE: bei klassifizierungsexperiment nach einteilung von wieland auch experiment mit einteilung nach epochenzugehörigkeit nach dichter (auch wenn das auch wieder nicht ganz unproblematisch ist, da dichter nicht immer gleichen stil haben müssen, z.b. morgenstern). diese experimente auch miteinander vergleichen um gucken, ob denn das gleiche signal gefunden wurde. dies wird verglichen, indem man die falsch klassifizierten autoren miteinander vergleicht. wenn jetzt die klassifizierung mit einteilung B besser war, müssten die fehlerhaften klassifizierungen von einteilung A betrachtet werden. sind z.B. gedichte von nietzsche fälschlicherweise durch zeiteinteilung von A zu naturalismus zugeordnet (obwohl laut B eigentlich zu jahrhundertwende), müsste klassifizierung von B angeschaut werden: ist das 


ÜBERBLEIBSEL
\begin{itemize}
    \item TODO: dhd paper 2019
    \item TODO zu Epocheneinteilung: \url{https://nlp.stanford.edu/courses/cs224n/2010/reports/sheldonc-yiam-colgrove.pdf}
    \item ENLEITUNG: welchen Klassen angehören, wobei die Klassen in diesem Fall durch Epochen dargestellt werden. Das Verfahren der computergestützten Textklassifikation gehört zu den sogenannten \textit{überwachten Lernverfahren}, was bedeutet, dass den Daten Klassen zugeordnet sein müssen \citep{russell2016}.
    \item \item Im Bereich des Natural Language Processing gehört die computergestützte Textklassifikation zu einem festen Bestandteil der gängigen Verfahren \citep[1]{kowsari2019}. Die Digital Humanities greifen oft auf Verfahren des Natural Language Processing zurück und so findet auch die Textklassifikation in Forschungsgebieten der Digital Humanities Anwendungsgebiete \citep{dhd2019} (TODO: lieber was anderes nehmen!). Dazu werden Klassifizierungsverfahren aus dem Bereich des Machine Learning verwendet (3.1 TODO). Sehr verbreite Machine Learning Klassifizierungsverfahren sind Logistic Regression und Support Vector Machines \citep[20f.]{kowsari2019}, was nicht zuletzt an der Einbindung in das beliebte Machine Learning Framework Scikit-Learn\footnote{Siehe \url{https://scikit-learn.org/stable/} (abgerufen am 19.05.2020).} liegt. In den letzten Jahren gewannen Neuronale Netze durch den Aufstieg von Deep Learning immer mehr an Bedeutung, da mit neuen Verfahren State-of-the-Art Ergebnisse in vielen Bereichen des Natural Language Processing, unter anderem auch der Textklassifikation, erreicht werden konnten \citep[3, 54]{kowsari2019}. Dies lag vor allem auch an dem Durchbruch der Word Embeddings \citep{mikolov2013}, die durch eine Projektion in einen semantischen Raum neue Repräsentationsmöglichkeiten von Worten und ihren Beziehungen zueinander ermöglichten. Ein weiterer Grund für den Erfolg der neuronalen Netze in den letzten Jahren war die Entwicklung von Sprachmodellen, bei dem sich vor allem das Sprachmodell BERT (TODO Devlin) durch eine Reihe von Rekorden in verschiedenen Natural Language Processing Problemen hervortat (AF!!) (3.2 TODO). Einige dieser Rekorde wurde kaum ein Jahr später von XLNet gebrochen \footnote{Siehe  \url{https://nlpprogress.com/english/text_classification.html} (abgerufen am 07.05.2020).}, welches einige Verbesserungen an BERT durchführte, viele Konzepte von BERT jedoch übernahm (TODO LIT) (3.2 TODO).
\end{itemize}


\pagebreak

\section{Einleitung} 
\label{einleitung}

Eine der Hauptaufgaben der Literaturgeschichte ist die Rekonstruktion derselben, welche mithilfe von repräsentativen Textkorpora sowie einer Periodisierung in \textit{Epochen} erfolgt \citep[405]{titzmann1991}. Titzmann definiert den Begriff der Epoche wie folgt:

\begin{quote}
Eine Epoche ist ein zeitlich begrenztes System, das wir von einer Menge von Texten abstrahieren und von dem wir behaupten, daß seine fundamentalen Merkmale bzw. Strukturen in diesem Zeitraum konstant bleiben \citep[405]{titzmann1991}. 
\end{quote}

Die Einteilung von Texten in Epochen kann von Literaturhistorikern manuell durchgeführt werden, wobei die Informationen über konstante Strukturen und Merkmale der Epochen auf inhaltlich-thematischer und formaler Ebene erfolgen \citep[6]{wieland2019}. Neben einer manuellen Zuweisung der Epochen ist es auch möglich, den Vorgang der manuellen Epocheneinteilung zu automatisieren. Dafür bietet sich das Verfahren der \textit{maschinellen Textklassifikation} an, bei dem ein maschinelles Lernverfahren anhand von bereits zugeordneten Klassen die Zugehörigkeit zu den entsprechenden Texten lernt. Für die Textklassifizierung stehen eine ganze Reihe von Verfahren zur Verfügung, die das Problem der Zuteilung von Klassen zu Texten auf verschiedene Weise lösen \citep{kowsari2019}. Ein Verfahren, was in jüngerer Vergangenheit für State-of-the-Art Ergebnisse in der Textklassifikationsforschung sowie weiteren Bereichen des Natural Language Processing sorgte, ist das Sprachmodell \textsc{BERT} \citep{devlin2018}. Ein Grund dafür war die Verwendung von kontextabhängigen \textit{word embeddings}, die es \textsc{BERT} erlauben, die Mehrdeutigkeit von Wörtern abzubilden. Ein weiterer Grund war die Bereitstellung von vortrainierten Modellen, die zuvor auf riesigen Textkorpora trainiert wurden und deren gelernte Informationen mithilfe des sogenannten \textit{fine-tunings} für die Verwendung von speziellen Aufgaben des Natural Language Processing wie der Textklassifikation transferiert werden können.

In dieser Arbeit soll anhand eines Lyrik-Korpus (Kapitel 2 (TODO)) untersucht werden, wie gut ein \textit{fine-tuned} \textsc{BERT} in der Lage ist, Gedichte der \textit{Frühen Moderne} den 
Subepochen\footnote{In dieser Arbeit wird der Begriff der \glqq Subepoche\grqq{} deckungsgleich mit dem Begriff \glqq literarische Strömung\grqq{} verwendet. Gemeint ist damit eine literarische Epoche oder Strömung, der eine literarische Epoche übergeordnet ist. So werden in dieser Arbeit die literarischen Strömungen \glqq Naturalismus\grqq{}, \glqq Jahrhundertwende\grqq{} und \glqq Expressionismus\grqq{} als Subepochen bezeichnet, da sie der Epoche \glqq Frühe Moderne\grqq{} untergeordnet sind (siehe auch Kapitel 4.1 (TODO)).} Naturalismus, Jahrhundertwende und Expressionismus zuzuordnen. Die Lyrik der Frühen Moderne hat zwei Eigenschaften, die eine Klassifizierung erschweren können. Zum einen sind die einzelnen Gedichte sehr kurz, wodurch nur wenige Features zur Trennung der Epochen zur Verfügung stehen (siehe Kapitel 4.3 TODO). Zum anderen unterscheidet sich das Vokabular der Frühen Moderne vom Vokabular der Texte, die als Trainingsgrundlage für viele vortrainierte Modelle verwendet wurden. Um dem zweiten Problem entgegenzuwirken, wurden neben den populären vortrainierten \textsc{BERT} Modellen TODO und TODO weitere vortrainierte Modelle verwendet und miteinander verglichen (Kapitel 3.1 (TODO), AF!, MEHR). Weiterhin sollte mithilfe einer Domänenadaption das Lyrik-Korpus selbst weiter trainiert werden, um das Vokabular des Korpus zu adaptieren und für die Klassifizierung verwenden zu können (Kapitel 4.4, TODO: habe ich das gemacht?). Neben \textsc{BERT} sollten noch die klassischen maschinellen Lernverfahren Logistic Regression und Support Vector Machines als Klassifizierungsverfahren verwendet werden (Kapitel 3.2 TODO). Da diese anders als \textsc{BERT} nicht auf vortrainierte Modelle zurückgreifen, sondern alle Informationen zur Klassifizierung lediglich aus dem Lyrik-Korpus erhalten, sollte als Gegenentwurf zu \textsc{BERT} geprüft werden, wie sich diese Art des Lernens für die Klassifizierung des Lyrik-Korpus eignete (TODO: kapitelverweis?).

Neben der eigentlichen Klassifizierung ist ein weiteres in dieser Arbeit behandelte Problem der Umgang mit den fehlenden Epochenannotationen des Lyrik-Korpus (Kapitel 4.1 TOD)). Da es nicht möglich war, jeden Text manuell einer Epoche zuzuordnen, wurden die Gedichte einmal nach Zeiträumen (Kapitel 4.1.1 TODO) und einmal nach Dichtern (4.1.2 TODO) aufgeteilt. Da beide so entstandene Epocheneinteilungen ein unausgeglichenes Korpus erzeugten, wurden zwei kleinere Korpora erstellt, die zwar eine reduzierte Anzahl an Gedichten, dafür aber eine ausgeglichenere Verteilung von Epochenzuordnungen enthielten (Kapitel 4.2 (TODO)). Für eine ausgewogenere Evaluation wurden bei den Klassifizierungsexperimenten deshalb beide Korpora verwendet.

TODO: mehr?

\section{Das Korpus}
\label{korpus}

Für die Experimente in dieser Arbeit wurde eine verkürzte Version des Deutschen Lyrik Korpus (DLK) von Thomas Haider und Steffen Eger verwendet \citep{haider2019}.\footnote{Es wurde hier die vierte Version des Korpus aus dem Github-Repository verwendet (siehe \url{https://github.com/tnhaider/DLK}. Alle Aussagen über das Korpus in dieser Arbeit gelten nur für diese Version.} Das ursprüngliche Korpus umfasst eine Zeitspanne von 1575 bis 1936 und somit mehrere literarische Epochen. Da in dieser Arbeit nur die Frühe Moderne und ihre literarischen Strömungen behandelt werden sollten, wurde das Korpus auf einen Zeitraum von 1880 bis 1933 gekürzt. Diese Epocheneinteilung richtet sich nach Klaus Wielands zeitlichen Einordnung der Frühen Moderne \citep[6f.]{wieland2019}. Das Korpus enthält für jedes Gedicht eine Gedichts-ID (\glqq PID\grqq{}), den Namen des Dichters (\glqq poet\grqq{}), den Titel des Gedichts (\glqq title\grqq{}), das Erscheinungsjahr (\glqq year\grqq{}), das Gedicht (\glqq poem\grqq{}) und die Länge des Gedichts (\glqq poemlength\grqq{}). Die Länge jedes Gedichts orientiert sich an den Anzahl der Tokens. Eine Epochenannotation ist nur für einige Gedichte verfügbar,\footnote{Das Korpus wurde aus verschiedenen Quellen zusammengesetzt und für das Teilkorpus ANTI-K sind Epochenannotationen verfügbar \citep[218]{haider2019}.} diese sind jedoch in dem zur Verfügung gestellten Korpus nicht vorhanden. Die Gedichte im ursprünglichen Korpus lagen in Stanzas vor und wurden für die Benutzung in dieser Arbeit in der richtigen Reihenfolge zusammengefügt. 1104 der 59424 zusammengesetzten Gedichte sind nicht vollständig. Gedichte, die aus weniger als 15 Tokens bestehen, wurden aus dem Korpus entfernt. Gedichte ohne Angaben zum Dichter und Gedichte ohne Inhalt wurden entfernt.

\section{Klassifizierungsverfahren}
\label{klassifizierungsverfahren}

\subsection{BERT}
\label{bert}

\textsc{BERT} steht für \glqq Bidirectional Encoder Representations from Transformers\grqq{} und brach bei seiner Veröffentlichung 2018 eine ganze Reihe von Rekorden für Aufgaben innerhalb des Natural Language Processing \citep{devlin2018}. (TODO MEHR?) BERT kann auf zwei Arten verwendet werden: \textit{feature-based}, bei welchem feste Features aus einem vortrainierten Modell extrahiert werden, und \textit{fine-tuned}, bei welchem dem vortrainierten Modell ein simpler Klassifizierungslayer hinzugefügt wird und alle Parameter gemeinsam für eine bestimmte Aufgabe wie der Textklassifikation \textit{fine-tuned} werden \citep[9]{devlin2018}. Die vortrainierten Modelle wurden durch ein Training auf einer umfangreichen Sammlung von unstrukturierten Textdaten erstellt. Beim Training verwendete \textsc{BERT} den sogenannten Attention-Mechanismus, der es erlaubt, relevanten Worten in einer Sequenz mehr Bedeutung als anderen Worten zuzuschreiben \citep{vaswani2017}. Anders als vorhergehende Implementierungen des Attention-Mechanismus verwendete BERT anstatt eines unidirektionalen einen bidirektionalen Ansatz, bei dem nicht nur nachfolgende, sondern auch vorhergehende Wörter betrachtet wurden. Der bidirektionale Ansatz ist jedoch problematisch:

\begin{quote}
[...] bidirectional conditioning would allow each word to indirectly
\glqq see itself\grqq{}, and the model could trivially predict the target word in a multi-layered context. \citep[4]{devlin2018}
\end{quote}

Zur Lösung dieses Problems benutzt \textsc{BERT} die Konzepte Next Sentence Prediction und Masked Language Modeling. Bei der Next Sentence Prediction (NSP) prüft \textsc{BERT}, ob ein nachfolgender Satz kontextuell zum vorherigen Satz passt. Beim Masked Language Modeling (MLM) werden zufällig 15\% der Wörter in jedem Satz der Trainingsdaten ausgewählt, von denen wiederum 80\% durch ein spezielles Maskierungstoken ausgetauscht, 10\% durch ein zufälliges Wort aus dem Vokabular des Korpus ersetzt und 10\% der Wörter nicht verändert wurden \citep[4]{devlin2018}. \textsc{BERT} versuchte dann im Training, die ausgewählten Tokens vorauszusagen, wozu es die umliegenden, nicht maskierten Wörter verwendete. Dadurch berücksichtigen die gelernten Gewichte anders als vorherige Wortrepräsentationen wie Bag-of-Words oder klassische Word Embeddings wie Word2Vec \citep{mikolov2013} den Kontext eines Wortes, was es \textsc{BERT} erlaubt, zwischen mehrdeutigen Wörtern zu unterscheiden. 

Die Auswirkung des Attention-Mechanismus soll an einem Beispiel verdeutlicht werden. In den folgenden vier Sätzen, von denen die ersten drei Sätze aus dem Lyrik-Korpus entnommen wurden, hat das Wort \glqq Bank\grqq{} zwei verschiedene Bedeutungen. In den ersten beiden Sätzen bezeichnet es ein Möbelstück und in den letzten beiden Sätzen ein Kreditinstitut.

\begin{enumerate}[label=\alph*.,leftmargin=3\parindent]
    \item Und hat sich auf die \textbf{Bank} gesetzt \\ (aus: \glqq Ohne Titel\grqq{} von Max Dauthendey (PID: 29870))
    \item Er begann auf eine \textbf{Bank} zu klettern. \\ (aus: \glqq Ohne Titel\grqq{} von Ludwig Thoma (PID: 8519))
    \item Millionen waren in der \textbf{Bank} geblieben \\ (aus: \glqq Bakkarat\grqq{} von Klabund (PID: 26394))
    \item Ich bringe mein Geld auf die \textbf{Bank}.
\end{enumerate}

Die Sätze wurden mithilfe von Bert und Word2Vec Embeddings in einem Vektorraum eingebettet, der mithilfe des Dimensionsreduktionsverfahrens t-SNE \citep{vandermaaten2008} auf zwei Dimensionen reduziert wurde (Abbildung 3 (TODO)). Es ist sehr gut zu erkennen, wie \textsc{BERT} die Mehrdeutigkeit von \glqq Bank\grqq{} abbildet (Abbildung 3, linke Seite (TODO)), die beiden verschiedenen Bedeutungen lassen sich deutlich voneinander unterscheiden. Anders sieht es hingegen bei den Word2Vec Embeddings aus (Abbildung 3, rechte Seite (TODO)), bei welchen das hervorgehobene Wort \glqq Bank\grqq{} und jedes andere Wort des Vokabulars nur einer Position zugeordnet wurden und keine Mehrdeutigkeit abgebildet wird.

\begin{minipage}{\textwidth}
\centering
\begin{figure}[H]
\centering
\includegraphics[width=1.0\linewidth]{figures/embeddings_comp.png}
\end{figure}
\begingroup
\captionof{figure}[Embedding des Wortes \glqq Bank\grqq{}]{Beide Abbildungen stellen den Vektorraum der Embeddings der Beispielsätze dar, der mithilfe des Verfahrens t-SNE auf zwei Dimensionen reduziert wurde. Die linke Abbildung zeigt nur die Positionen der 768-dimensionalen \textsc{BERT} Embeddings für das Wort \glqq Bank\grqq{}, wobei die unterschiedlichen Bedeutungen farblich hervorgehoben wurden. Die rechte Abbildung stellt die Positionen der 300-dimensionalen Word2Vec Embeddings von allen Wörtern der Beispielsätze dar. Die Position des Wortes \glqq Bank\grqq{} wurde hervorgehoben.}
\endgroup
\end{minipage}
\bigskip

\noindent Ursprünglich wurde \textsc{BERT} auf englischen Texten trainiert, wodurch nur englische vortrainierte Modelle zur Verfügung standen \citep[5]{devlin2018}. Heutzutage stehen jedoch einige deutschsprachige Modelle zur Verfügung, in Tabelle 1 (TODO) werden die Modelle aufgelistet, die in dieser Arbeit verwendet wurden.\footnote{Alle aufgelisteten Modelle sind bei Huggingface zu finden, siehe \url{https://huggingface.co/transformers/pretrained_models.html} (abgerufen am 10.06.2020).} Beide Modelle wurden auf sehr unterschiedlichen Textkorpora trainiert. Während \textsc{BERT}\textsubscript{DEUTSCH} vorwiegend auf neuzeitlichen Texten trainiert wurde, wurde \textsc{BERT}\textsubscript{REDE} auf historischen Texten zwischen 1840 und 1920 trainiert.\footnote{Siehe \url{https://huggingface.co/redewiedergabe/bert-base-historical-german-rw-cased} (abgerufen 14.06.2020).}

\bigskip
\begin{minipage}{\textwidth}
\small
\def\arraystretch{1.2}
\noindent
\begin{tabularx}{\textwidth}{|l|l|X|}
\hline
& \textbf{Abkürzungsname} & \textbf{Eigenschaften} \\\hline
\textbf{\textsc{BERT}\textsubscript{DEUTSCH}} & \textit{bert-base-german-dbmdz-cased} & Trainiert auf deutschen Wikipedia Artikeln, dem EU Buchhandlung Korpus, dem OpenSubtitles Korpus, dem CommonCrawl Korpus, dem ParaCrawl Korpus und dem News Crawl Korpus.\\\hline
\textbf{\textsc{BERT}\textsubscript{REDE}} & \textit{bert-base-historical-german-rw-cased} & Trainiert auf narrativen Texten der Digitalen Bibliothek, Märchen und Sagen aus dem Grimm Korpus, Zeitungs- und Zeitschriftenartikel aus dem Mannheimer Korpus Historischer Zeitungen und Zeitschriften, Zeitschriftenartikel aus der Zeitschrift \glqq Die Grenzboten\grqq{} und fiktionale und nicht-fiktionale Texte aus dem Projekt Gutenberg. Alle Texte sind historische Texte aus dem Zeitraum 1840 bis 1920.\\\hline
\end{tabularx}
\begingroup
\captionof{table}[Deutschsprachige vortrainierte \textsc{BERT}-Modelle]{Die Tabelle stellt die in dieser Arbeit verwendeten vortrainierten \textsc{BERT}-Modelle dar, die bei Huggingface zur Verfügung stehen. Die Bezeichnungen links sind die Bezeichnungen für die Modelle, die in dieser Arbeit verwendet werden und nicht die Originalnamen. Die Abkürzungsnamen von Huggingface befinden sich in der zweiten Spalte. In der letzten Spalte werden Eigenschaften der vortrainierten Modelle genannt.}
\endgroup
\end{minipage}

\subsection{Maschinelle Lernverfahren}
\label{maschinelle_lernverfahren}

Für die Experimente in dieser Arbeit wurden neben \textsc{BERT} die Machine Learning Verfahren Logistic Regression und Support Vector Machines zur Epochenklassifikation verwendet. Sie sind etablierte Verfahren, die schon seit Jahrzehnten zur Textklassifikation verwendet werden \citep[3, 20f.]{kowsari2019}. Anders als bei \textsc{BERT} werden diese Verfahren nicht auf bereits trainierten Gewichte \textit{fine-tuned}, sondern 
\textit{\glqq from scratch\grqq{}} trainiert, d.h. alle Informationen, die zur Klassifizierung verwendet werden, werden lediglich aus dem Trainingsdatensatz gewonnen. Diese Art des Lernens ist auch mit Sprachmodellen möglich, jedoch erfordert dies eine Menge an Rechenressourcen, die für diese Arbeit nicht zur Verfügung stehen. Wie auch bei den Sprachmodellen werden bei den Machine Learning Verfahren die einzelnen Wörter der Texte vektorisiert. Ein typisches Vektorisierungsverfahren ist das Bag-of-Words Modell, bei dem Wörter durch ihre absoluten Häufigkeiten repräsentiert werden. Diese Häufigkeiten werden in hochdimensionale, dünnbesetzte Vektoren umgewandelt. Inhaltlich wird ein Wort dadurch nur durch seine Häufigkeit in den Texten dargestellt, weitere Eigenschaften des Wortes wie seine Mehrdeutigkeit oder kontextabhängige Semantik entfallen.

Die Experimente mit den Machine Learning Verfahren sollten ein Gegenentwurf zum Ansatz der Klassifizierung mit den \textit{fine-tuned} \textsc{BERT}-Modellen darstellen, da sie auf Informationen aus vortrainierten Modellen verzichten und stattdessen nur die Informationen aus dem Lyrik-Korpus zur Klassifizierung der Epochen verwenden. Weiterhin sollte überprüft werden, wie hoch die Auswirkung der simpleren Darstellung der Wörter durch hochdimensionale, dünnbesetzte Vektoren im Vergleich zu den weniger hochdimensionalen, dichtbesetzten Vektoren der Sprachmodelle hinsichtlich der Klassifizierungsgenauigkeit ausfiel.\footnote{Es ist auch möglich, dichtbesetzte Word Embeddings in Kombination mit Machine Learning Verfahren zu verwenden, wie z.B. in diesem Blogpost gezeigt wird: \url{http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/} (abgerufen 19.05.2020). Diese Vorgehensweise wird in dieser Arbeit jedoch nicht verwendet.} Anstelle des klassischen Bag-of-Words Ansatzes, der nur die einfachen Termhäufigkeiten berücksichtigt, wurde eine Gewichtung der Häufigkeiten mit TF-IDF angewandt, bei dem die Häufigkeit eines Wortes im Verhältnis zur Häufigkeit im gesamten Korpus berücksichtigt und gegebenenfalls niedriger gewichtet wird.

TODO: noch mehr? oder reicht?

\section{Problemstellung}
\label{problemstellung}

Das DLK-Korpus weist einige Besonderheiten auf, die eine Klassifizierung erschweren. Dies liegt zum einen an der Zusammenstellung des DLK-Korpus, zum anderen an der literarischen Gattung \glqq Lyrik\grqq{} und der Epoche der Frühen Moderne. Die Besonderheiten sowie der Verweis auf die Kapitel, in denen die Lösungsansätze erläutert werden, sind im Folgenden aufgelistet:

%TODO: evtl minipage
\begin{enumerate}[label=\alph*),leftmargin=3\parindent]
    \item \textbf{Fehlende Epochenannotationen}. Das DLK-Korpus besitzt keine Epochenannotationen. Eine nachträgliche Ergänzung der Epochen ist möglich, jedoch nicht ganz unproblematisch. Lösungsansätze werden in Kapitel 4.1 (TODO) ausführlich erläutert.
    \item \textbf{Ungleiche Verteilung der Gedichte pro Epoche}. Sobald die Gedichte bestimmten Epochen zugeordnet wurden, fällt auf, dass die Anzahl der Gedichte pro Subepoche ungleich verteilt ist. Eine gleiche Verteilung der Gedichte pro Epoche kann mit \textit{Downsampling} erreicht werden (Kapitel 4.2 TODO).
    \item \textbf{Sehr kurze Texte}. Lyrische Werke zeichnen sich oft durch ihre Kürze aus, die durchschnittliche Länge eines Gedichts im Lyrik-Korpus ist 160 Tokens. Dies ist für eine Textklassifizierung mitunter problematisch, da nicht genügend Merkmale zur Unterscheidung der Klassen zur Verfügung stehen können. Lösungsansätze werden in Kapitel 4.3 (TODO) gegeben.
    \item \textbf{Wandel des Vokabular}. Viele vortrainierte Modelle von \textsc{BERT} wurden auf Texten der jüngeren Vergangenheit trainiert. Das Vokabular dieser Modelle unterscheidet sich jedoch vom Vokabular des Lyrik-Korpus aus der Frühen Moderne und viele alte, unbekannte Wörter wurden bei diesen Modellen nicht trainiert (AF?). Eine mögliche Lösung neben der Verwendung von vortrainierten Modellen, die auf historischen Texten trainiert wurden, ist die \textbf{Domänenadaption} (Kapitel 4.4 (TODO)).
\end{enumerate}

\subsection{Epocheneinteilung}
\label{epocheneinteilung}

Das DLK-Lyrik Korpus enthält keine Annotationen zu den Epochen oder literarischen Strömungen, die literarischen Strömungen für die Frühe Moderne wurden nachträglich hinzugefügt. Eine literaturwissenschaftliche Einteilung von Werken in eine Epoche oder Subepoche richtet nach einer Menge von Kriterien wie z.B. dem Inhalt eines Werkes, dem Verfasser, der Zeit, in der es entstanden ist, der Struktur des Textes oder anderen Werken des Verfassers \citep{titzmann1991}. Diese Art der Einteilung erfordert jedoch eine Menge an Domänenwissen und zeitlichem Aufwand, was im Rahmen der Untersuchungen in dieser Arbeit nicht möglich war. Stattdessen wurden zwei verschiedene Herangehensweisen zur Unterteilung der Gedichte der Frühen Moderne in die verschiedenen literarischen Strömungen verwendet, die im Folgenden näher erläutert werden.

\subsubsection{Einteilung nach Zeiträumen}
\label{einteilung_nach_zeiträumen}

Eine gängige Einteilungsmöglichkeit von Texten nach literarischen Strömungen erfolgt anhand der Erscheinungsjahre. Dabei wird angenommen, dass alle Werke, die innerhalb des Zeitraums einer literarischen Strömung oder Epoche entstanden sind, auch dieser literarischen Strömung oder Epoche angehören. Diese Zeiträume werden von Literaturwissenschaftlern festgelegt und können sich voneinander unterscheiden. In dieser Arbeit wird die Aufteilung von Klaus Wieland verwendet \citep{wieland2019}, welche in der linken Spalte von Tabelle 2 (TODO) dargestellt wird. Diese Einteilung kann jedoch für die Klassifizierungsexperimente in dieser Arbeit nicht unverändert übernommen werden, da sich der Naturalismus und die Jahrhundertwende überschneiden und Werke nur einer Epoche zugeordnet werden sollten.\footnote{In dieser Arbeit wird angenommen, dass ein Werk nur einer einzigen Epoche angehören kann.} In der rechten Spalte von Tabelle 2 (TODO) wird daher eine leicht veränderte Einteilung dargestellt. Die Grenzen der literarischen Strömung \glqq Expressionismus\grqq{} wurden von Wieland übernommen.\footnote{Für die Klassenbezeichnung wurde in dieser Arbeit \glqq Expressionismus und Dadaismus\grqq{} zu \glqq Expressionismus\grqq{} zusammengefasst.} Die literarische Strömung \glqq Neue Sachlichkeit\grqq{} ist im Korpus von Haider und Eger mit nur einem Werk vertreten und wurde deshalb für diese Arbeit entfernt. Aufgrund der Überschneidung wurde der Beginn der \glqq Jahrhundertwende\grqq{} um zwei Jahre nach hinten und das Ende des \glqq Naturalimus\grqq{} um neun Jahre nach vorne verschoben. Der Grund für die Grenzsetzung im Jahr 1892 waren die Dichter Max Dauthendey und Christian Morgenstern. Bei einer Betrachtung der Verteilung der Erscheinungsjahre der Gedichte im Korpus ist das Jahr 1892 das Jahr mit den am meisten veröffentlichten Gedichten (Abbildung 1 (TODO)). Mehr als 87\% der veröffentlichten Gedichte in diesem Jahr stammen von Max Dauthendey und Christian Morgenstern, deren Werke eher dem Stilpluralismus der Jahrhundertwende als dem Naturalismus zugeordnet werden \citep{dauthendey, morgenstern}. 

\bigskip
\small
\def\arraystretch{1.2}
\noindent
\begin{tabular}{|c|c|c|}
\hline
& \textbf{Einteilung nach Wieland} & \textbf{veränderte Einteilung} \\\hline
\textbf{Naturalismus} & 1880-1900 & 1880-1891 \\\hline
\textbf{Jahrhundertwende} & 1890-1910 & 1892-1910  \\\hline
\makecell{\textbf{Expressionismus} \\ \textbf{und Dadaismus}} & 1910-1925 & 1910-1925 \\\hline
\textbf{Neue Sachlichkeit} & 1925-1933 & - \\\hline 
\end{tabular}
\begingroup
\captionof{table}[Einteilung der literarischen Strömungen der Frühen Moderne]{Einteilung der literarischen Strömungen innerhalb der Frühen Moderne nach Klaus Wieland \citep{wieland2019}. Die linke Seite stellt die vorgeschlagene Einteilung nach Wieland dar und die rechte Seite die für diese Arbeit veränderte Unterteilung.}
\endgroup
\bigskip

\begin{minipage}{\textwidth}
\centering
\begin{figure}[H]
\centering
\includegraphics[width=1.0\linewidth]{figures/publication_1982.png}
\end{figure}
\begingroup
\captionof{figure}[Verteilung der Gedichte nach Erscheinungsjahren]{Die Grafik links zeigt die Verteilung der Gedichte nach Erscheinungsjahren. Das Jahr mit den meisten Gedichten (1892) wurde hervorgehoben. Rechts befindet sich eine nach der Anzahl der in diesem Jahr veröffentlichten Gedichte absteigend sortierte Liste von Dichtern für das Jahr 1892.}
\endgroup
\end{minipage}
\bigskip

\noindent Die Unterteilungsmethode nach Zeiträumen ist nicht unproblematisch. Einige Probleme werden im Folgenden aufgelistet:

\begin{enumerate}[leftmargin=3\parindent]
    \item \textbf{Wechsel von literarischen Strömungen}. Literarische Strömungen sind wie ihre übergeordneten Epochen zwar an bestimmte Zeiträume gebunden, jedoch lässt sich der Wechsel von Epochen nicht eindeutig an bestimmten Jahreszahlen oder Tagen festmachen. Der Übergang von einer (Sub-)Epoche zur anderen (Sub-)Epoche ist ein genetischer Prozess und kein einschneidendes Ereignis \citep[41f.]{titzmann2012}.
    \item \textbf{Koexistenz von literarischen Strömungen}. Literarische Strömungen können parallel zueinander existieren. Ein Beispiel dafür ist der Naturalismus und die Jahrhundertwende, die nach Wielands Einteilung zehn Jahre lang parallel verlaufen sind \citep{wieland2019}.
    \item \textbf{Zugehörigkeit von Werken zu einer literarischen Strömungen}. Werke, die während dem Zeitraum einer literarischen Strömung entstanden sind, müssen nicht unbedingt dieser literarischen Strömung angehören. 
\end{enumerate}

\noindent Um zu verhindern, dass diese Probleme die Klassifizierungsergebnisse der Experimente zu stark verfälschen würden, wurde zusätzlich eine alternative Einteilungsmethode gewählt, die im Folgenden beschrieben wird.

\subsubsection{Einteilung nach Dichtern}
\label{einteilung_nach_dichtern}

Neben der Einteilung nach Zeiträumen ist es auch möglich, eine Einteilung anhand von Dichtern vorzunehmen. Dabei wird bestimmt, welcher Epoche die Werke des Dichters vorwiegend zugeordnet werden. Diese Einteilung wurde händisch mithilfe von Wielands Zuordnung \citep{wieland2019} und der Deutschen Biographie zugeordnet.\footnote{\url{https://www.deutsche-biographie.de/} (abgerufen am 13.05.2020).} Wenn aus den Informationsquellen keine Zugehörigkeit zu einer literarischen Strömung ermittelt werden konnte, wurde die Einteilung der literarischen Strömungen nach Zeiträumen verwendet. Bei mehreren möglichen Strömungen wurde die literarische Strömung ausgewählt, der die meisten Werke des jeweiligen Dichters zugeordnet wurden. Bei der Einteilung nach Dichtern wurden etwa 50\% der literarischen Strömungen anders zugeteilt als bei der Einteilung nach Zeiträumen. Zudem enthielt diese Einteilung die literarische Strömung \glqq Neue Sachlichkeit\grqq{}. Da sich diese Subepoche aber beinahe nur aus Werken von Kurt Tucholsky zusammensetzte, wurden alle Werke, die dieser Epoche zugeordnet wurden, aus dem Korpus entfernt. Weiterhin wurden Werke, die bei der Einteilung nach Dichtern literarischen Strömungen zugeteilt wurden, die nicht zur Auswahl von Wieland gehören, entfernt. Wie auch bei der Unterteilung nach Zeiträumen ist diese Unterteilung nicht unproblematisch. So ist es möglich, dass der Autor Werke innerhalb verschiedener (Sub-)Epochen verfasst hat und diese prägend für die jeweiligen (Sub-)Epochen waren.

\subsection{Downsampling}
\label{Downsampling}

Sowohl die Einteilung der Subepochen nach Zeiträumen als auch die Einteilung nach Dichtern erzeugten eine unausgeglichene Klassenverteilung (Abbildung 3 TODO). Es wurden deshalb die stark vertretenen Klassen mithilfe von zufälligem \textit{Downsampling} an die kleinste Klasse angepasst. Das \textit{Downsampling} wurde einmal für die Einteilung nach Zeiträumen und die Einteilung nach Dichtern durchgeführt. Das Ergebnis waren zwei Korpora, die im Verlauf dieser Arbeit zur besseren Unterscheidung \glqq EY-Korpus\grqq{} (= epoch\_year-Korpus) und \glqq EP-Korpus\grqq{} (= epoch\_poet-Korpus) betitelt wurden. Jede literarische Strömung des EY-Korpus bestand nach dem \textit{Downsampling} nur noch aus 282 Instanzen, während jede literarische Strömung des EP-Korpus nach dem \textit{Downsampling} durch 1000 Instanzen vertreten war. Das kleinere EY-Korpus ist hinsichtlich der Aufteilung der Strömungen nach Zeiträumen und Dichtern für beide Einteilungsverfahren ausgewogen (Abbildung 3 (TODO), zweite Zeile), während das EP-Korpus hinsichtlich der Einteilung nach Zeiträumen stark unausgeglichen ist (Abbildung 3 (TODO), dritte Zeile). 

\begin{minipage}{\textwidth}
\centering
\begin{figure}[H]
\includegraphics[width=1.0\linewidth]{figures/poem_distribution.png}
\end{figure}
\begingroup
\captionof{figure}[Verteilung der Gedichte pro Epoche]{Die Abbildung stellt die Verteilung der Gedichte pro Epoche dar. Die erste Reihe zeigt links die Verteilung der Epochen, eingeteilt nach Zeiträumen (= epoch\_year) und rechts die Verteilung der Epochen, welche nach Dichtern eingeteilt ist (= epoch\_poet). Die anderen vier Grafiken zeigen die Verteilungen der Gedichte nach der Aufteilung in die zwei unterschiedlich verteilten Korpora \glqq EY-Korpus\grqq{} (= epoch\_year-Korpus) und \glqq EP-Korpus\grqq{} (= epoch\_poet-Korpus), die jeweils in einer eigenen Reihe dargestellt werden. Zu jedem Korpus wird die Verteilung nach epoch\_year (links) und nach epoch\_poet (rechts) angezeigt.}
\endgroup
\end{minipage}

\subsection{Umgang mit kurzen Texten}

Die durchschnittliche Länge eines Gedichts im Lyrik-Korpus ist 160 Tokens. Bei der Textklassifizierung lernen die Verfahren die Unterschiede der Klassen anhand von Features, die oft die einzelnen Wörter (Tokens) der Texte sind. Umso weniger Wörter den Textklassifizierungsverfahren zur Verfügung stehen, desto schwieriger wird ein Unterscheidung der Klassen und desto mehr fallen die einzelnen Wörter ins Gewicht. Hier könnten die \textsc{BERT}-Embeddings hilfreich sein, die die wenigen Worte durch eine kontextabhängige Repräsentation stärker voneinander unterscheiden, wodurch mehr unterschiedliche Features dargestellt werden können als durch die TF-IDF-Gewichtung der maschinellen Verfahren. Die \textsc{BERT}-Embeddings können ohne eine Modifikation jedoch nur Texte von maximal 512 Tokens behandeln \citep[13]{devlin2018}, was für viele Textgattungen problematisch sein kann. Längere Gedichte wurden in dieser Arbeit mithilfe der \glqq head+tail\grqq{} Methode von Chi u.a. \citep[199]{chi2019} trunkiert, bei welcher die ersten 128 und letzten 382 Tokens als Textrepräsentation verwendet wurden. Die maximale Anzahl an Tokens wurde für diese Arbeit auf 256 Tokens reduziert, das Verhältnis der Trunkierung wurde jedoch beibehalten, d.h. die 64 ersten und die 192 letzten Tokens wurden zur Repräsentation verwendet. Neben Performance-Gründen war diese Reduktion auch der Tatsache geschuldet, dass die tatsächliche Maximalanzahl an Tokens von \textsc{BERT} nicht direkt 512 Tokens sind, da \textsc{BERT} unbekannte Worte mithilfe von \glqq Teiltokens\grqq{} repräsentiert. Dies wird durch den folgenden Satz aus dem Gedicht \glqq Robinson zimmert einen Stuhl\grqq{} von Maria Luise Weissmann deutlich, der mithilfe von \textsc{BERT}\textsubscript{DEUTSCH} kodiert wurde:

\medskip
\begin{addmargin}[7em]{5em}
{\fontfamily{pbk}\selectfont 
    Ich lehre schwer die ungeübten Hände \\
    Ich, le, \#\#hre, schwer, die, unge, \#\#übt, \#\#en, Hände
}
\end{addmargin}
\medskip

\noindent Die \textsc{BERT}-Embeddings berücksichtigen bei der Wortrepräsentation den Kontext des Wortes. Bei den Experimenten mit den Machine Learning Verfahren wurden keine Word Embeddings verwendet, stattdessen wurden N-Gramme verwendet, um in einer einfacheren Form den Kontext eines Wortes zu berücksichtigen (AF?). 

\subsection{Domänenadaption}
\label{domänenadapation}

Mit einem distributionellen Semantikmodell fand Herbelot 2014 heraus, dass sich die Kohärenz von Poesie signifikant von der Kohärenz in Wikipedia-Artikeln unterscheidet \citep{herbelot2014}. Dies ist für das \textit{fine-tuning} von \textsc{BERT} mithilfe eines vortrainierten Modells auf dem Lyrik-Korpus von Nachteil, da die meisten vortrainierten Modelle wie das Modell \textsc{BERT}\textsubscript{DEUTSCH} auf Wikipedia-Artikeln und anderen Texten der jüngeren Vergangenheit trainiert wurden (siehe Tabelle 1 (TODO) in Kapitel 3.1). Auch das Vokabular der vortrainierten Modelle unterscheidet sich vom Vokabular des Lyrik-Korpus, viele Wörter im Lyrik-Korpus sind den vortrainierten Modellen unbekannt. Eine mögliche Lösung ist eine \textbf{Domänenadaption} des Lyrik-Korpus. Dabei wird das Masked Language Modeling (Kapitel 3.1) von \textsc{BERT} auf nicht annotierten Texten aus der gewünschten Domäne weiter trainiert \citep[76]{ma2019}. Das daraus resultierende Modell ist eine Erweiterung des bestehenden vortrainierten Modells, welches durch die Domänenadaption im Idealfall allgemeine Informationen über die Domäne gelernt hat. Die angepassten Gewichte werden dann für die Klassifizierung verwendet.

Für die Evaluierung des Trainings des Masked Language Modeling wird die \textit{perplexity} verwendet. Diese misst, wie gut ein probabilistisches Modell eine bestimmte Stichprobe voraussagt \citep[106]{goldberg2017}. Je kleiner die \textit{perplexity} ist, desto sicherer ist das Modell bei einer Voraussage. In dieser Arbeit wird die Perplexity mit der Formel $e^{\text{CE}}$ berechnet,\footnote{Diese Berechnung wurde von der \textit{transformers}-Bibliothek übernommen, siehe \url{https://github.com/huggingface/transformers/blob/5e7fe8b5853fd72287e93194fc8be8c39008b6e3/examples/language-modeling/run_language_modeling.py} (abgerufen am 15.06.2020).} wobei $\text{CE}$ für die Kreuzentropie steht. Die Kreuzentropie ist ein Maß zur Bewertung der Qualität eines Modells für eine Wahrscheinlichkeitsverteilung und wird im Machine Learning als Verlustfunktion verwendet \citep[27]{goldberg2017}. Für die Messung der \textit{perplexity} wurde das Lyrik-Korpus in einen Trainings- und Testdatensatz aufgeteilt und die \textit{perplexity} wurde einmal vor der Domänenadaption auf dem Testdatensatz gemessen und einmal danach. Die Ergebnisse sind in Tabelle 3 (TODO) dargestellt. TODO: ergebnisse interpretieren



\bigskip
\small
\def\arraystretch{1.2}
\noindent
\begin{tabular}{|l|c|c|}
\hline
& \textbf{Ohne Domänenadaption} & \textbf{Mit Domänenadaption} \\\hline
\textbf{\textsc{BERT}\textsubscript{DEUTSCH}} &  &  \\\hline
\textbf{\textsc{BERT}\textsubscript{REDE}} &  &   \\\hline
\end{tabular}
\begingroup
\captionof{table}[Perplexity Werte der Domänenadaption der vortrainierten \textsc{BERT} Modelle]{Die Tabelle stellt die \textit{perplexity} Werte für das Masked Language Modeling der beiden vortrainierten \textsc{BERT} Modelle dar.}
\endgroup

\section{Experimente}
\label{experimente}

\subsection{Aufbau}
\label{aufbau}

Für die Experimente wurde das Lyrik-Korpus in zwei Korpora aufgeteilt (siehe Kapitel 4.1 und 4.2). Für die Klassifizierung mit den \textsc{BERT}-Modellen wurde die \textsc{Transformers}-Bibliothek von Huggingface verwendet,\footnote{Siehe \url{https://huggingface.co/} (abgerufen am 15.06.2020).} für die Klassifizierung mit den Machine Learning Experimenten die Bibliothek \textsc{Scikit-learn}.\footnote{Siehe \url{https://scikit-learn.org/stable/} (abgerufen am 15.06.2020).}



kreuzvalidierung (5.3)

\bigskip

TODO

\begin{itemize}
    \item erwähnen, dass pretrained modelle utnerschiedlich sind
    \item domänenadaption auf lyrik korpus
    \item HILFE: Notebook mit text classifications beispiel zu bert (\url{https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb})
    \item params für BERT: Now that we have our model loaded we need to grab the training hyperparameters from within the stored model. For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the BERT paper): Batch size: 16, 32
    Learning rate (Adam): 5e-5, 3e-5, 2e-5
    Number of epochs: 2, 3, 4
    \item n-gramme werden bei ml auch in gridsearch gesucht
\end{itemize}


\subsection{Hyperparameteroptimierung}
\label{hyperparameteroptimierung}

Für die Experimente sollte eine Hyperparameteroptimierung durchgeführt werden. Während bei den Machine Learning Experimenten die Hyperparameteroptimierung für jedes Korpus und jede Klasse durchgeführt wurde, war dies bei den \textsc{BERT} Experimenten zu zeitintensiv, weshalb nur die Hyperparameter der besten Modelle der beiden Korpora optimiert wurden. Die zu optimierenden Parameter und ihre Suchräume werden in Tabelle 4 (TODO) dargestellt. Einige Hyperparameter wie der \glqq loss\grqq{} der Linearen SVM oder der \glqq solver\grqq{} der Logistic Regression wurden zuvor festgelegt. Für beide Modelle wurden insgesamt 18000 Modelle trainiert und evaluiert, da auch noch nach N-Grammen optimiert wurde (TODO: siehe Kapitel 5.1). 

\bigskip
\small
\def\arraystretch{1.2}
\noindent
\begin{tabular}{|c|c|c|}
\hline
& Parameter & Suchräume \\\hline
\textbf{\textsc{BERT}} 
    & \begin{minipage}[t]{0.4\textwidth}
        \begin{itemize}[nosep,after=\strut]
            \item TODO
            \item ...
        \end{itemize}
    \end{minipage} 
  & \begin{minipage}[t]{0.4\textwidth}
        \begin{itemize}[nosep,after=\strut]
            \item TODO
        \end{itemize}
    \end{minipage}  \\
\hline
\textbf{Lineare SVM} 
    & \begin{minipage}[t]{0.4\textwidth}
        \begin{itemize}[nosep,after=\strut]
            \item penalty
            \item loss
            \item tol
            \item C
            \item max\_iter
            \item class\_weight
        \end{itemize}
    \end{minipage} 
  & \begin{minipage}[t]{0.4\textwidth}
        \begin{itemize}[nosep,after=\strut]
            \item l2
            \item squared\_hinge
            \item 1e-5, 1e-3
            \item 1, 3, 5, 7, 9
            \item 1000, 3000, 5000
            \item None, balanced
        \end{itemize}
    \end{minipage} \\\hline    
\textbf{Logistic Regression} 
    & \begin{minipage}[t]{0.4\textwidth}
        \begin{itemize}[nosep,after=\strut]
            \item penalty
            \item tol
            \item C
            \item solver
            \item max\_iter
            \item class\_weight
        \end{itemize}
    \end{minipage} 
  & \begin{minipage}[t]{0.4\textwidth}
        \begin{itemize}[nosep,after=\strut]
            \item l1, l2
            \item 1e-5, 1e-3
            \item 1, 3, 5, 7, 9
            \item liblinear
            \item 1000, 3000, 5000
            \item None, balanced
        \end{itemize}
    \end{minipage}  \\
\hline
\end{tabular}
\begingroup
\captionof{table}[Parameter der Klassifizierungsverfahren und ihre Suchräume]{Die Tabelle stellt die Parameter der Klassifizierungsverfahren und Suchräume dar.}
\endgroup
\bigskip


\bigskip
TODO: BERT: parameter: epochs (1-4), learning rate (3 werte), batch size (4, 8)


\subsection{Evaluation}
\label{evaluation}

Als Evaluationsverfahren wurde in dieser Arbeit die stratifizierte, $k$-fache Kreuzvalidierung verwendet. Bei diesem Verfahren wird der Datensatz in $k$ gleich große Datensätze aufgeteilt, von denen $k\!-\!1$ als  Trainingsdatensätze und ein Datensatz als Testdatensatz behandelt werden. Durch eine Stratifizierung wird sicher gestellt, dass jeder dieser Teildatensätzen eine annähernd gleiche Verteilung aller Klassen besitzt. Ein Modell wird dann auf den zusammengeführten Trainingsdatensätzen trainiert und auf dem, während des Trainings zurückgehaltenen Testdatensatz evaluiert. Die Aufteilung in $k$ Datensätze wird $k$-mal durchgeführt, sodass jeder Teildatensatz einmal die Rolle des Testdatensatzes innehat. Durch eine $k$-fache Kreuzvalidierung wird gewährleistet, dass ein Modell unter fairen Bedingungen auf dem gesamten Datensatz evaluiert wird, da der Testdatensatz bei jedem Durchgang wechselt und sogenanntes \glqq Peeking\grqq{} (deutsch: Spähen) verhindert wird \citep[708f.]{russell2016}. Zudem wird der Testdatensatz weder zum Vor- noch zum Nachteil einer Evaluierung ausgewählt und der Einfluss eines einzelnen Testdatensatzes auf die Klassifizierungsgenauigkeit wird gedämpft.


In dieser Arbeit wurde für jeden der $k$ Durchgänge ein gewichteter $F_1$-Wert ermittelt. Das $F_1$-Maß ist ein Maß zur Bestimmung der Klassifizierungsgenauigkeit, welches die Evaluationsmetriken \textit{Precision} und \textit{Recall} mittels des harmonischen Mittels kombiniert \citep[869]{russell2016}. Als Gewichtung wurde die \textit{Macro}-Gewichtung verwendet, bei welcher \textit{Precision} und \textit{Recall} für jede Klasse separat berechnet und anschließend gemittelt werden. Dadurch bleibt eine ungleiche Verteilung der Klassen unberücksichtigt \citep[430]{sokolova2009}. Von den $k$ $F_1$-Werten aller Durchgänge wurde der Mittelwert gebildet. Dieser Mittelwert wurde in dieser Arbeit \glqq \textit{cv}-Wert\grqq{} genannt und zur Beurteilung der Klassifizierungsgenauigkeit der verschiedenen Verfahren verwendet. 

In Kombination mit der Suche nach den optimalen Hyperparametern (Abschnitt 6.2) wurden bei den Machine Learning Experimenten eine verschachtelte Kreuzvalidierung\footnote{Dabei wählt die \glqq innere\grqq{} Kreuzvalidierung auf Basis der zu untersuchenden Hyperparameter das beste Modell aus und die \glqq äußere\grqq{} Kreuzvalidierung misst die Performance des jeweils besten Modells.} durchgeführt, indem die zu optimierenden Hyperparameter, die Suchräume sowie eine Pipeline mit der TF-IDF-Vektorisierung und dem jeweiligen Klassifizierungsverfahren der Kreuzvalidierung übergeben wurde. Durch die verschachtelte Kreuzvalidierung sollte eine möglichst unverfälschte Bewertung der Machine Learning Klassifizierungsverfahren gewährleistet werden. Für die Experimente mit \textsc{BERT} war dies zu zeitintensiv, weshalb nur eine einfache Kreuzvalidierung durchgeführt wurde und die Hyperparameteroptimierung nur für die besten Modelle der beiden Korpora durchgeführt wurde.

\section{Ergebnisse}
\label{ergebnisse}

TODO

\bigskip
\small
% \centering
\noindent
\begin{tabular}{|l|l|l||l|l|}
\hline
    \multirow{1}{*}{} &
      \multicolumn{2}{c||}{\textbf{EY-Korpus}} & \multicolumn{2}{c|}{\textbf{EP-Korpus}} \\\cline{2-5}
      
        & Zeitraum & Dichter &  Zeitraum & Dichter \\
        \thickhline
        \textbf{\textsc{BERT}} &  &  &  & \\
        \text{Deutsch} &  &  &  & \\
        \text{Rede} &  &  &  & \\
        \hline
        \textbf{\textsc{BERT}} + \textbf{Domänenadaption} &  &  &  & \\
        \text{Deutsch} &  &  &  & \\
        \text{Rede} &  &  &  & \\
        \hline
        \textbf{Lineare SVM} &  &  &  & \\\hline
        \textbf{Logistic Regression} &  &  &  & \\\hline
\end{tabular}
\begingroup
\captionof{table}[TODO]{TODO}
\endgroup
\bigskip

\begin{itemize}
    \item evtl. Gedichte von Autoren zusammenfassen (die in einem Jahr verfasst worden sind wie bei clustering). das ebenfalls testen   
    \item 
\end{itemize}


\section{Schlussbetrachtung}
\label{schlussbetrachtung}

TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Literaturverzeichnis wird 
%% automatisch eingefügt
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\lhead{}
\printbibliography
\addcontentsline{toc}{section}{\bibname}

\pagebreak
\begin{appendices}
\section{Daten und Code}
\label{appendix_a}

TODO



TODO

\end{appendices}
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Eidesstattliche Erklärung
%% muss angepasst werden 
%% in Erklaerung.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{Erklaerung.tex}

\end{document}
